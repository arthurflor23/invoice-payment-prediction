{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsbVQyYHCLQ/ziNB3j2oh5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RhtPjoHTq7BZ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount('./gdrive', force_remount=True)\n","%cd './gdrive/My Drive/Colab Notebooks/cubricks'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_uqEobEKvHp8","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","seed = 42"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jeBrT3TrvQ6h","colab_type":"code","colab":{}},"source":["def plot_countplot(df, cols, title=None, rotation=0):\n","    for col in cols:\n","        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 2))\n","        g = sns.countplot(np.squeeze(df[col]), ax=ax)\n","        g.set_xticklabels(labels=g.get_xticklabels(), rotation=rotation)\n","        g.set_title(title)\n","\n","def plot_confuncion_matrix(y_test, predict, title='Confusion Matrix', report=True):\n","    if report: print(classification_report(y_test, y_predict))\n","    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 8))\n","    g = sns.heatmap(confusion_matrix(y_test, predict), fmt='d', square=True, annot=True, cmap='Blues', ax=ax)\n","    g.set_title(title)\n","\n","def plot_feature_importance(features, importances):\n","    features = np.array(features)\n","    indices = np.argsort(importances)[::-1]\n","    print(f'Feature ranking:')\n","\n","    for f in range(len(features)):\n","        print(f'{importances[indices[f]]}\\t{features[indices[f]]}')\n","\n","    plt.figure(figsize=(10, 8))\n","    plt.barh(range(len(features)), importances[indices])\n","    plt.yticks(range(len(features)), features[indices])\n","    plt.title('Feature Importance')\n","    plt.gca().invert_yaxis()\n","    plt.show()\n","\n","def setup_buckets(df, col, bins, sufix='Bucket'):\n","    bins = [-np.inf] + bins + [np.inf]\n","    labels = [f'{bins[i]} to {bins[i+1]-1}' for i in range(len(bins[:-1]))]\n","    df[col + sufix + 'Category'] = pd.cut(df[col], bins=bins, labels=labels, right=False, include_lowest=True)\n","    df[[col + sufix]] = df[[col + sufix + 'Category']].apply(lambda x: pd.Categorical(x, ordered=True).codes)\n","    return df\n","\n","def split_data_month_window(df, col, date, month_window):\n","    date_0 = pd.to_datetime(date)\n","    date_1 = date_0 - pd.DateOffset(months=month_window)\n","    date_2 = date_0 + pd.DateOffset(months=1)\n","\n","    train = df[(df[col] >= date_1) & (df[col] < date_0)]\n","    test = df[(df[col] >= date_0) & (df[col] < date_2)]\n","\n","    train.reset_index(drop=True, inplace=True)\n","    test.reset_index(drop=True, inplace=True)\n","    return train, test\n","\n","def classifier_predict(classifier, x_test, threshold=0.5):\n","    return (classifier.predict_proba(x_test)[:,1] >= threshold).astype('int')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faoC-yeX30uK","colab_type":"code","colab":{}},"source":["### Read dataset ###\n","df = pd.read_csv('InvoicedDocuments_v5.csv', sep=';', na_values=['N/I'], parse_dates=['DocumentDate', 'DueDate', 'ClearingDate'])\n","\n","### First filters ###\n","df.dropna(subset=['ClearingDate', 'PaymentTerms'], inplace=True)\n","df = df[(df['DueDate'] > df['DocumentDate']) & (df['ClearingDate'] > df['DocumentDate'])]\n","df = df[df['DocumentDate'] >= '2018-03-01']\n","\n","df.sort_values(by=['DocumentDate'], ascending=True, ignore_index=True, inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","### Fix numerical columns ###\n","for amount, count in zip(['InvoicedAmount', 'PaidAmount', 'PaidPastAmount', 'OpenAmount', 'PastDueAmount'],\n","                         ['InvoicedDocuments', 'PaidDocuments', 'PaidPastDocuments', 'OpenDocuments', 'PastDueDocuments']):\n","    df[amount] = df[amount] / df[count]\n","    df[[amount, count]] = df[[amount, count]].fillna(0)\n","\n","avg_cols = ['AvgDSOPastDueDocuments', 'AvgPastDueDays']\n","df[avg_cols] = df[avg_cols].fillna(0)\n","\n","### Extract date information ###\n","date_int = lambda x: x.astype('timedelta64[D]').astype(int)\n","\n","for col in ['DocumentDate', 'DueDate']:\n","    df[col + 'DayOfYear'] = pd.DatetimeIndex(df[col]).dayofyear\n","    df[col + 'Month'] = pd.DatetimeIndex(df[col]).month\n","    df[col + 'Day'] = pd.DatetimeIndex(df[col]).day\n","    df[col + 'WeekDay'] = pd.DatetimeIndex(df[col]).weekday\n","\n","### Days to DueDate ###\n","df['DocumentDateToDueDate'] = date_int(df['DueDate'] - df['DocumentDate'])\n","### Days to MonthEnd ###\n","df['DocumentDateToMonthEnd'] = date_int((df['DocumentDate'] + pd.offsets.MonthEnd(1)) - df['DocumentDate'])\n","df['DueDateToMonthEnd'] = date_int((df['DueDate'] + pd.offsets.MonthEnd(1)) - df['DueDate'])\n","### Days to ClearingDate ###\n","df['DueDateToClearingDate'] = date_int(df['ClearingDate'] - df['DueDate'])\n","df['DocumentDateToClearingDate'] = date_int(df['ClearingDate'] - df['DocumentDate'])\n","\n","\n","### Categorical columns ###\n","df['CustomerRegion'].fillna(df['CustomerRegion'].value_counts().idxmax(), inplace=True)\n","\n","category_cols = ['CompanyKey', 'CustomerKey', 'CorporateDivision', 'CustomerRegion', 'PaymentTerms',]\n","df[category_cols] = df[category_cols].apply(lambda x: pd.Categorical(x, ordered=False).codes)\n","\n","# for col in category_cols:\n","#     value_counts = df[col].value_counts()\n","#     # index_list = value_counts[int(len(value_counts) * 0.75):].index\n","#     index_list = value_counts[value_counts < value_counts.mean() * 0.001].index\n","#     df[col] = df[col].apply(lambda x: 'Other' if x in index_list else x)\n","\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fP16s6QURXQ","colab_type":"code","colab":{}},"source":["df['CustomerRegion'].value_counts().values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ETafw3HDVMk","colab_type":"code","colab":{}},"source":["df = setup_buckets(df, col='DueDateToClearingDate', bins=[1], sufix='Bin')\n","df = setup_buckets(df, col='DueDateToClearingDate', bins=[1, 4, 7], sufix='Bucket')\n","# df = setup_buckets(df, col='DueDateToClearingDate', bins=[-1, 1], sufix='Bin')\n","# df = setup_buckets(df, col='DueDateToClearingDate', bins=[-7, -4, -3, -2, -1, 0, 1, 2, 3, 5, 8], sufix='Bucket')\n","\n","plot_countplot(df, cols=['DueDateToClearingDateBinCategory', 'DueDateToClearingDateBucketCategory'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XSHX4q-JCTg","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import RobustScaler, QuantileTransformer, PowerTransformer, Normalizer, StandardScaler\n","\n","\n","def prepare_data(train, test, y_column, x_column, num_first=None, random_state=None):\n","    randomize = np.arange(train.shape[0])\n","    np.random.seed(random_state)\n","    np.random.shuffle(randomize)\n","\n","    y_column, x_column = np.array(y_column), np.array(x_column)\n","    x_train, y_train = train[x_column].values[randomize], train[y_column].values[randomize]\n","    x_test, y_test = test[x_column].values, test[y_column].values\n","\n","    if num_first is not None:\n","        x_train[:,:num_first] = np.vectorize(np.log)(x_train[:,:num_first] + 1)\n","        x_test[:,:num_first] = np.vectorize(np.log)(x_test[:,:num_first] + 1)\n","\n","        qt = RobustScaler(quantile_range=(5, 95))\n","        qt.fit(np.concatenate((x_train[:,:num_first], x_test[:,:num_first])), np.concatenate((y_train, y_test)))\n","\n","        x_train[:,:num_first] = qt.transform(x_train[:,:num_first])\n","        x_test[:,:num_first] = qt.transform(x_test[:,:num_first])\n","\n","    return x_train, y_train, x_test, y_test\n","\n","\n","y_column = ['DueDateToClearingDateBin']\n","x_column = [\n","            'AvgPastDueDays',\n","            'AvgDSOPastDueDocuments',\n","            # 'PaidDocuments',\n","            # 'PaidAmount',\n","            # 'InvoicedDocuments',\n","            # 'InvoicedAmount',\n","            # 'OpenDocuments',\n","            # 'OpenAmount',\n","            # 'PaidPastDocuments',\n","            'PastDueAmount',\n","            'PaidPastAmount',\n","            # 'PastDueDocuments',\n","            'DocumentAmount',\n","            'DocumentDateToDueDate',\n","                'CompanyKey',\n","                'PaymentTerms',\n","                'CorporateDivision',\n","                'CustomerKey',\n","                'CustomerRegion',\n","            'DocumentDateDay',\n","            'DocumentDateWeekDay',\n","            'DocumentDateDayOfYear',\n","            # 'DocumentDateToMonthEnd',\n","            # 'DocumentDateMonth',\n","            'DueDateDay',\n","            'DueDateWeekDay',\n","            'DueDateDayOfYear',\n","            # 'DueDateToMonthEnd',\n","            # 'DueDateMonth',\n","            ]\n","\n","\n","train, test = split_data_month_window(df, col='DueDate', date='2020-08-01', month_window=12)\n","\n","x_train, y_train, x_test, y_test = prepare_data(train, test, y_column, x_column, num_first=6, random_state=seed)\n","\n","plot_countplot(train, cols=['DueDateToClearingDateBinCategory'], title='Train')\n","plot_countplot(test, cols=['DueDateToClearingDateBinCategory'], title='Test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6iwNiRfJsIu","colab_type":"code","colab":{}},"source":["clf = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=seed, n_jobs=-1)\n","clf.fit(x_train, np.squeeze(y_train))\n","\n","y_predict = classifier_predict(clf, x_test, threshold=0.5)\n","\n","plot_confuncion_matrix(test[y_column].values, y_predict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzXzNE8He53H","colab_type":"code","colab":{}},"source":["y_predict = classifier_predict(clf, x_test, threshold=0.9999)\n","\n","plot_confuncion_matrix(test[y_column].values, y_predict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lBUeM4lC-hm5","colab_type":"code","colab":{}},"source":["plot_feature_importance(x_column, clf.feature_importances_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3ZQWO0Bf5mn","colab_type":"code","colab":{}},"source":["print(test[test['DueDateToClearingDateBin'] == 1]['DocumentAmount'].max())\n","print(test[y_predict == 1]['DocumentAmount'].max(), '\\n')\n","\n","print(test[test['DueDateToClearingDateBin'] == 1]['DocumentAmount'].describe(), '\\n')\n","print(test[y_predict == 1]['DocumentAmount'].describe())"],"execution_count":null,"outputs":[]}]}