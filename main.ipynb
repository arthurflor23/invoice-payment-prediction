{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predict-payments.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"BVjbCCPxi52t","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V6k_MfpBjFLB","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","\n","drive.mount('./gdrive', force_remount=True)\n","%cd './gdrive/My Drive/cubricks'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9lbF8JLW2nU","colab_type":"code","colab":{}},"source":["import datetime\n","import functools\n","import multiprocessing\n","import numpy as np\n","import pandas as pd\n","\n","\n","class CSVManager():\n","    def __init__(self):\n","        self.df = None\n","        self.bins = None\n","        self.labels = None\n","\n","    def read(self, filename, sep=';', na_values=['N/I'], orderby=None, ascending=True):\n","        self.df = pd.read_csv(filename, sep=sep, na_values=na_values)\n","\n","        if orderby is not None:\n","            self.df.sort_values(by=orderby, ascending=ascending, ignore_index=True, inplace=True)\n","\n","    def save(self, name, sep=';', na_rep=-1):\n","        self.df.to_csv(name, sep=sep, na_rep=na_rep, float_format='%g', index=False)\n","\n","    def info(self):\n","        print(self.df.info())\n","\n","    def head(self, value=10):\n","        print(self.df.head(value))\n","\n","    def null_sum(self):\n","        print(self.df.isnull().sum())\n","\n","    def ppnan(self, dropna_cols=None, fillna_cols=None, fillna_value=None):\n","        if dropna_cols:\n","            self.df.dropna(subset=dropna_cols, inplace=True)\n","        if fillna_cols is not None and fillna_value is not None:\n","            self.df[fillna_cols] = self.df[fillna_cols].fillna(fillna_value)\n","        elif fillna_value is not None:\n","            self.df.fillna(value=fillna_value, inplace=True)\n","\n","    def set_ratio(self, dividend_cols, divisor_cols):\n","        for dividend, divisor in zip(dividend_cols, divisor_cols):\n","            ratio_col = 'Ratio' + dividend + divisor\n","            self.df[ratio_col] = self.df[dividend] / self.df[divisor]\n","            self.df[ratio_col].fillna(0, inplace=True)\n","\n","    def set_daysto(self, source_cols, target_cols):\n","        for src, tgt in zip(source_cols, target_cols):\n","            delta_col = 'DaysTo' + tgt\n","            self.df[delta_col] = self.df[tgt] - self.df[src]\n","            self.df[delta_col].fillna(pd.Timedelta(seconds=0), inplace=True)\n","            self.df[delta_col] = self.df[delta_col].astype('timedelta64[D]').astype(int)\n","            self.df[delta_col] = self.df[delta_col].clip(lower=0)\n","\n","    def set_range(self, bins, cols):\n","        self.bins = bins + [np.inf]\n","        self.labels = [f'{self.bins[i]}-{self.bins[i+1]-1}' for i in range(len(self.bins[:-1]))]\n","\n","        for col in cols:\n","            self.df[col + 'Range'] = pd.cut(self.df[col], bins=self.bins, labels=self.labels, right=False, include_lowest=True)\n","            self.df[[col + 'RangeCT']] = self.df[[col + 'Range']].apply(lambda x: pd.Categorical(x, ordered=True).codes)\n","\n","    def extract_days(self, cols):\n","        for col in cols:\n","            self.df[col + 'Month'] = self.df[col].dt.month\n","            self.df[col + 'Day'] = self.df[col].dt.day\n","            self.df[col + 'WeekDay'] = self.df[col].dt.weekday\n","\n","    def minmax_filter(self, min_cols, max_cols):\n","        for mi, ma in zip(min_cols, max_cols):\n","            self.df = self.df[self.df[mi] < self.df[ma]]\n","\n","    def cast_to_number(self, cols):\n","        self.df = self.df.apply(lambda x: [int(''.join(format(ord(w), '') for w in str(y)))\n","                                           if not str(y).isnumeric() else y for y in x] if x.name in cols else x)\n","\n","    def cast_to_integer(self, cols):\n","        self.df = self.df.apply(lambda x: pd.to_numeric(x, downcast='integer') if x.name in cols else x)\n","\n","    def cast_to_date(self, cols):\n","        self.df = self.df.apply(lambda x: pd.to_datetime(x, errors='coerce') if x.name in cols else x)\n","\n","    def get_data_range(self, col, date, month_window):\n","        date_0 = pd.to_datetime(date)\n","        date_1 = date_0 - pd.DateOffset(months=month_window)\n","        date_2 = date_0 + pd.DateOffset(months=1)\n","        train = self.df[(self.df[col] >= date_1) & (self.df[col] < date_0)]\n","        test = self.df[(self.df[col] >= date_0) & (self.df[col] < date_2)]\n","        return train, test\n","\n","    def calculate_per_bucket(self, bucket_col, amount_col, date_col, key_col, month_window):\n","        self.df.reset_index(drop=True, inplace=True)\n","        dflocal = self.df[[bucket_col, amount_col, date_col, key_col]].copy()\n","\n","        month_window = pd.DateOffset(months=month_window)\n","        arange_labels = np.arange(len(self.labels))\n","\n","        min_month = dflocal[date_col].min()\n","        max_month = dflocal[date_col].max()\n","        one_month = pd.DateOffset(months=1)\n","        results = []\n","\n","        while min_month <= max_month:\n","            records = dflocal[(dflocal[date_col] >= min_month - month_window) & (dflocal[date_col] < min_month + one_month)]\n","            curr_month = records[records[date_col] >= min_month].values\n","\n","            batch = f'{min_month.year}-{min_month.month}/{max_month.year}-{max_month.month}'\n","            print(f'Preprocessing {curr_month.shape[0]} items ({batch})', end=' ')\n","\n","            with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n","                start_time = datetime.datetime.now()\n","                r = pool.map(functools.partial(self.apply_multiprocessing, records, arange_labels,\n","                                               month_window, bucket_col, amount_col, date_col, key_col), curr_month)\n","                print(f'~ {datetime.datetime.now() - start_time}')\n","                results.extend(r)\n","                pool.close()\n","                pool.join()\n","\n","            min_month += one_month\n","\n","        new_cols = np.array([[f'Range{i}Amount', f'Range{i}Count'] for i in arange_labels])\n","        results = pd.DataFrame(np.array(results), columns=new_cols.flatten())\n","\n","        self.df.drop(labels=new_cols.flatten(), axis=1, inplace=True, errors='ignore')\n","        self.df = pd.concat([self.df, results], axis=1)\n","\n","    @staticmethod\n","    def apply_multiprocessing(*args):\n","        records, arange_labels, month_window, bucket_col, amount_col, date_col, key_col, row = args\n","        t = records[(records[date_col] >= row[2] - month_window) & (records[date_col] < row[2]) & (records[key_col] == row[3])]\n","\n","        total_a = t[amount_col].mean()\n","        total_b = t[bucket_col].count()\n","        result = []\n","\n","        for i in arange_labels:\n","            a = t[t[bucket_col] == i][amount_col].mean()\n","            b = t[t[bucket_col] == i][bucket_col].count()\n","\n","            mean = (a / total_a) if total_a > 0 else -1\n","            count = (b / total_b) if total_b > 0 else -1\n","            result.extend([mean, count])\n","\n","        return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Utks3V-BW9T8","colab_type":"code","colab":{}},"source":["# csv = CSVManager()\n","# csv.read('InvoicedDocuments_v4.csv', orderby=['DocumentDate'])\n","# csv.ppnan(dropna_cols=['ClearingDate'], fillna_value=0)\n","\n","# csv.cast_to_number(cols=['CustomerRegion', 'PaymentTerms'])\n","# csv.cast_to_integer(cols=['InvoicedDocuments', 'PaidDocuments', 'PaidPastDocuments', 'OpenDocuments', 'PastDueDocuments'])\n","# csv.cast_to_date(cols=['CustomerLastCreditReview', 'DocumentDate', 'DueDate', 'ClearingDate'])\n","\n","# csv.minmax_filter(min_cols=['DocumentDate', 'DocumentDate'], max_cols=['DueDate', 'ClearingDate'])\n","# csv.extract_days(cols=['DocumentDate', 'DueDate'])\n","\n","# csv.set_ratio(dividend_cols=['InvoicedAmount', 'PaidAmount', 'PaidPastAmount', 'OpenAmount', 'PastDueAmount'],\n","#               divisor_cols=['InvoicedDocuments', 'PaidDocuments', 'PaidPastDocuments', 'OpenDocuments', 'PastDueDocuments'])\n","\n","# csv.set_daysto(source_cols=['DocumentDate', 'DocumentDate', 'CustomerLastCreditReview'],\n","#                 target_cols=['DueDate', 'ClearingDate', 'DocumentDate'])\n","\n","# csv.set_range(bins=list(range(1, 31, 28)), cols=['DaysToDueDate', 'DaysToClearingDate'])\n","\n","# csv.calculate_per_bucket(bucket_col='DaysToClearingDateRangeCT', amount_col='DocumentAmount',\n","#                           date_col='DocumentDate', key_col='CustomerKey', month_window=2)\n","\n","# csv.save(name='InvoicedDocuments_v4_pp.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wCWTUG489XCY","colab_type":"code","colab":{}},"source":["csv = CSVManager()\n","csv.read('InvoicedDocuments_v4_pp.csv', orderby=['DocumentDate'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyKb64gTjLmF","colab_type":"code","colab":{}},"source":["!pip install -q tensorflow-gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuHnDFfqjXwb","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE8dkdKQmqsq","colab_type":"code","colab":{}},"source":["def get_feature_importance(features, importances, plot=False):\n","  indices = np.argsort(importances)[::-1]\n","  print(f'Feature ranking:')\n","\n","  for f in range(x_train.shape[1]):\n","    print(f'{importances[indices[f]]}\\t{features[indices[f]]}')\n","\n","  if plot:\n","    plt.figure(figsize=(10, 8))\n","    plt.barh(range(x_train.shape[1]), importances[indices])\n","    plt.yticks(range(x_train.shape[1]), features[indices])\n","    plt.title('Feature Importance')\n","    plt.gca().invert_yaxis()\n","    plt.show()\n","\n","def get_report(y_test, predict, plot=False):\n","  print(f'Total items: {len(y_test)}')\n","  print(f'Accuracy: {accuracy_score(y_test, predict) * 100:.2f}%\\n')\n","\n","  # cm_report = classification_report(y_test, predict, target_names=labels)\n","  # print(cm_report)\n","\n","  if plot:\n","    cm = confusion_matrix(y_test, predict)\n","    plt.figure(figsize=(10, 10))\n","    sns.heatmap(cm/cm.sum(axis=0), square=True, annot=True, fmt='.2%', cmap='Blues', xticklabels=labels, yticklabels=labels)\n","\n","def plot_buckets(x1, x2=None):\n","  if x2 is None:\n","    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30, 4))\n","    sns.countplot(x1, ax=ax)\n","  else:\n","    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(30, 4))\n","    sns.countplot(x1, ax=ax[0])\n","    sns.countplot(x2, ax=ax[1])\n","\n","def set_ratio(df, cols):\n","    for col in cols:\n","        ratio_col = 'Ratio' + col[0] + col[1]\n","        df[ratio_col] = df[col[0]] / df[col[1]]\n","        df[ratio_col].fillna(0, inplace=True)\n","    return df\n","\n","def set_daysto(df, cols):\n","    for col in cols:\n","        delta_col = 'DaysTo' + col[1]\n","        df[delta_col] = df[col[1]] - df[col[0]]\n","        df[delta_col].fillna(pd.Timedelta(seconds=0), inplace=True)\n","        df[delta_col] = df[delta_col].astype('timedelta64[D]').astype(int)\n","        df[delta_col] = df[delta_col].clip(lower=0)\n","    return df\n","\n","def set_days(df, cols):\n","    for col in cols:\n","        df[col + 'Month'] = df[col].dt.month\n","        df[col + 'Day'] = df[col].dt.day\n","        df[col + 'WeekDay'] = df[col].dt.weekday\n","    return df\n","\n","def set_range_cols(df, bins, labels, cols):\n","    for col in cols:\n","        df[col + 'Range'] = pd.cut(df[col], bins=bins, labels=labels, right=False, include_lowest=True)\n","        df[[col + 'RangeCT']] = df[[col + 'Range']].apply(lambda x: pd.Categorical(x, ordered=True).codes)\n","    return df\n","\n","def get_data_range(df, col, date, window_month):\n","    date_0 = pd.to_datetime(date)\n","    date_1 = date_0 - pd.DateOffset(months=window_month)\n","    date_2 = date_0 + pd.DateOffset(months=1)\n","\n","    train = df[(df[col] >= date_1) & (df[col] < date_0)]\n","    test = df[(df[col] >= date_0) & (df[col] < date_2)]\n","\n","    return train, test\n","\n","def binary_encoding(df, cols):\n","    for col in cols:\n","        bincol = np.array([str('{0:b}'.format(x)) for x in df[col[1]].values])\n","        header = np.array([f'{col[1]}{i}' for i in range(col[0])])\n","        newcol = np.zeros((bincol.shape[0], col[0]), dtype=np.int8)\n","\n","        for i in range(bincol.shape[0]):\n","            a = np.array(list(bincol[i]), dtype=np.int8)\n","            newcol[i][col[0] - len(a):] = a\n","\n","        df2 = pd.DataFrame(newcol, columns=header)\n","        df.reset_index(drop=True, inplace=True)\n","        df = pd.concat([df, df2], axis=1)\n","        df.drop(columns=[col[1]], inplace=True)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_u5F1zHFgcHX","colab_type":"code","colab":{}},"source":["### Read data ###\n","df = pd.read_csv('InvoicedDocuments_v4.csv', sep=';', na_values=['N/I'])\n","df.sort_values(by=['DocumentDate'], ascending=True, ignore_index=True, inplace=True)\n","\n","### Fill NaN data ###\n","df.dropna(subset=['ClearingDate'], inplace=True)\n","df.fillna(0, inplace=True)\n","\n","### Generate ratio ###\n","df = set_ratio(df, cols=[('InvoicedAmount', 'InvoicedDocuments'),\n","                         ('PaidAmount', 'PaidDocuments'),\n","                         ('PaidPastAmount', 'PaidPastDocuments'),\n","                         ('OpenAmount', 'OpenDocuments'),\n","                         ('PastDueAmount', 'PastDueDocuments')])\n","\n","## String to number ###\n","cols = ['CustomerRegion', 'PaymentTerms']\n","df = df.apply(lambda x: [int(''.join(format(ord(w), '') for w in str(y))) for y in x] if x.name in cols else x)\n","\n","### Convert columns to integer columns ###\n","cols = ['InvoicedDocuments', 'PaidDocuments', 'PaidPastDocuments', 'OpenDocuments', 'PastDueDocuments']\n","df = df.apply(lambda x: pd.to_numeric(x, downcast='integer') if x.name in cols else x)\n","\n","### Convert columns to date columns ###\n","cols = ['CustomerLastCreditReview', 'DocumentDate', 'DueDate', 'ClearingDate']\n","df = df.apply(lambda x: pd.to_datetime(x, errors='coerce') if x.name in cols else x)\n","\n","### Setup 'DaysTo' columns ###\n","df = df[(df['DocumentDate'] < df['DueDate']) & (df['DocumentDate'] < df['ClearingDate'])]\n","\n","df = set_daysto(df, cols=[('DocumentDate', 'DueDate'),\n","                          ('DocumentDate', 'ClearingDate'),\n","                          ('CustomerLastCreditReview', 'DocumentDate')])\n","\n","### Setup Month, Day and WeekDay columns ###\n","df = set_days(df, cols=['DocumentDate', 'DueDate'])\n","\n","### Setup range columns ###\n","bins = [1, 8, 15, 22, 29, np.inf]\n","labels = [f'{bins[i]}-{bins[i+1]-1}' for i in range(len(bins[:-1]))]\n","df = set_range_cols(df, bins, labels, cols=['DaysToDueDate', 'DaysToClearingDate'])\n","\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAVj-UMkfcDs","colab_type":"code","colab":{}},"source":["# bins = [1, 8, 15, 22, 29, np.inf]\n","bins = list(range(1, 31, 28)) + [np.inf]\n","\n","labels = [f'{bins[i]}-{bins[i+1]-1}' for i in range(len(bins[:-1]))]\n","df = set_range_cols(df, bins, labels, cols=['DaysToDueDate', 'DaysToClearingDate'])\n","\n","plot_buckets(df['DaysToClearingDateRange'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fsY3aG_xwUe7","colab_type":"code","colab":{}},"source":["y_column = np.array(['DaysToClearingDateRangeCT'])\n","features = np.array([\n","                     'CompanyKey',\n","                     'CustomerKey',\n","                     'CustomerRegion',\n","                    ##  CustomerLastCreditReview,\n","                    ##  'DocumentDate',\n","                    ##  'DueDate',\n","                    ##  'ClearingDate',\n","                     'PaymentTerms',\n","                    ##  'DocumentNumber',\n","                     'DocumentAmount',\n","                    #  'InvoicedDocuments',\n","                    #  'InvoicedAmount',\n","                    #  'PaidDocuments',\n","                    #  'PaidAmount',\n","                    #  'PaidPastDocuments',\n","                    #  'PaidPastAmount',\n","                    #  'OpenDocuments',\n","                    #  'OpenAmount',\n","                    #  'PastDueDocuments',\n","                    #  'PastDueAmount',\n","                     'AvgDSOPastDueDocuments',\n","                     'PastDueDays',\n","                     'DaysToDueDate',\n","                    #  'DaysToDocumentDate',\n","                    ##  'DaysToClearingDate',\n","                    #  'DocumentDateMonth',\n","                    #  'DocumentDateDay',\n","                     'DocumentDateWeekDay',\n","                    #  'DueDateMonth',\n","                    #  'DueDateDay',\n","                     'DueDateWeekDay',\n","                    ##  'DaysToDueDateRange', \n","                    #  'DaysToDueDateRangeCT',\n","                    ##  'DaysToClearingDateRange',\n","                    #  'DaysToClearingDateRangeCT',\n","                     'RatioInvoicedAmountInvoicedDocuments',\n","                    #  'RatioPaidAmountPaidDocuments',\n","                    #  'RatioPaidPastAmountPaidPastDocuments',\n","                    #  'RatioOpenAmountOpenDocuments',\n","                     'RatioPastDueAmountPastDueDocuments',\n","                     ])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9VBu8dpC_QX","colab_type":"code","colab":{}},"source":["import multiprocessing\n","\n","class BucketGenerator:\n","  def __init__(self, labels, window_month=2):\n","    self.labels = np.arange(len(labels))\n","    self.window_month = pd.DateOffset(months=window_month)\n","\n","  def clearing_per_bucket(self, df, workers=4):\n","    new_features = [[f'Range{i}Amount', f'Range{i}Count'] for i in self.labels]\n","    df = self.apply_by_multiprocessing(df, self.per_bucket, axis=1, workers=workers)\n","    df.fillna(-1, inplace=True)\n","    return df, np.array(new_features).flatten()\n","\n","  def apply_by_multiprocessing(self, df, func, **kwargs):\n","      workers = kwargs.pop('workers')\n","      pool = multiprocessing.Pool(processes=workers)\n","      result = pool.map(_apply_df, [(d, func, kwargs) for d in np.array_split(df, workers)])\n","      pool.close()\n","      return pd.concat(list(result))\n","\n","  def _apply_df(self, args):\n","      df, func, kwargs = args\n","      return df.apply(func, **kwargs)\n","\n","  def per_bucket(self, x):\n","    t = df[(df['DocumentDate'] >= x['DocumentDate'] - self.window_month) & (df['DocumentDate'] < x['DocumentDate']) & (df['CustomerKey'] == x['CustomerKey'])]\n","    total_m = t['DocumentAmount'].mean()\n","    total_c = t['DaysToClearingDateRangeCT'].count()\n","\n","    for i in self.labels:\n","      m = t[t['DaysToClearingDateRangeCT'] == i]['DocumentAmount'].mean()\n","      c = t[t['DaysToClearingDateRangeCT'] == i]['DaysToClearingDateRangeCT'].count()\n","      x[new_features[i][0]] = (m/total_m) if total_m > 0 else -1\n","      x[new_features[i][1]] = (c/total_c) if total_c > 0 else -1\n","    return x\n","\n","\n","train, test = get_data_range(df, col='DocumentDate', date='2020-08-01', window_month=4)\n","\n","bg = BucketGenerator(labels, 2)\n","train = bg.clearing_per_bucket(train)\n","\n","# train, new_features = clearing_per_bucket(train, ct=labels, window_month=2)\n","# # test, new_features = clearing_per_bucket(test, ct=labels, window_month=2)\n","\n","# train, test = get_data_range(train, col='DocumentDate', date='2020-07-01', window_month=2)\n","# test, new_features = clearing_per_bucket(test, ct=labels, window_month=2)\n","\n","# features = np.append(features, new_features)\n","\n","# x_train, y_train = train[features].values, train[y_column].values\n","# x_test, y_test = test[features].values, test[y_column].values\n","\n","# plot_buckets(train['DaysToClearingDateRange'], test['DaysToClearingDateRange'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3uTDQklm4nE","colab_type":"code","colab":{}},"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","random_forest = GradientBoostingClassifier(n_estimators=1000, criterion='friedman_mse', min_weight_fraction_leaf=1e-4, random_state=42)\n","random_forest.fit(x_train, np.squeeze(y_train))\n","\n","predict = random_forest.predict(x_test)\n","\n","get_report(y_test, predict, plot=True)\n","get_feature_importance(features, random_forest.feature_importances_, plot=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejDhMCmBjzRG","colab_type":"code","colab":{}},"source":["# fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(30, 5))\n","# sns.heatmap(train[features].corr(), square=True, annot=False, fmt='.1g', vmin=-1, vmax=1, center=0, cmap='Pastel1', ax=ax[0])\n","# sns.heatmap(test[features].corr(), square=True, annot=False, fmt='.1g', vmin=-1, vmax=1, center=0, cmap='Pastel1', ax=ax[1])\n","\n","print(f'Due Date Predict')\n","get_report(y_test, test[\"DaysToDueDateRangeCT\"].values, plot=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnukmcZaD_-K","colab_type":"code","colab":{}},"source":["random_forest = RandomForestClassifier(n_estimators=10, criterion='entropy', min_weight_fraction_leaf=1e-4, random_state=42)\n","random_forest.fit(x_train, np.squeeze(y_train))\n","\n","predict = random_forest.predict(x_test)\n","\n","get_report(y_test, predict, plot=True)\n","get_feature_importance(features, random_forest.feature_importances_, plot=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6x04OXg_Yav","colab_type":"code","colab":{}},"source":["# from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV\n","# from scipy.stats import uniform, randint\n","# import xgboost as xgb\n","\n","\n","# def display_scores(scores):\n","#     print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n","\n","# def report_best_scores(results, n_top=3):\n","#     for i in range(1, n_top + 1):\n","#         candidates = np.flatnonzero(results['rank_test_score'] == i)\n","#         for candidate in candidates:\n","#             print(\"Model with rank: {0}\".format(i))\n","#             print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n","#                   results['mean_test_score'][candidate],\n","#                   results['std_test_score'][candidate]))\n","#             print(\"Parameters: {0}\".format(results['params'][candidate]), \"\\n\")\n","\n","\n","# xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n","# params = {\n","#     \"colsample_bytree\": uniform(0.7, 0.3),\n","#     \"gamma\": uniform(0, 0.5),\n","#     \"learning_rate\": uniform(0.003, 0.3), \n","#     \"max_depth\": randint(2, 6),\n","#     \"n_estimators\": randint(10, 150),\n","#     \"subsample\": uniform(0.6, 0.4)\n","# }\n","\n","\n","# # search = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=100, cv=3, verbose=1, n_jobs=-1, return_train_score=True)\n","# # search.fit(x_train, np.squeeze(y_train))\n","# # report_best_scores(search.cv_results_, 1)\n","\n","\n","# # x_train, x_valid, y_train, y_valid = train_test_split(train[features].values,\n","# #                                                       train[y_column].values,\n","# #                                                       test_size=0.1, \n","# #                                                       shuffle=True,\n","# #                                                       random_state=42,\n","# #                                                       stratify=train[y_column].values)\n","\n","# # xgb_model.fit(x_train, y_train, early_stopping_rounds=10, eval_set=[(x_valid, y_valid)])\n","\n","\n","# xgb_model = xgb.XGBClassifier(max_depth=5,\n","#                               learning_rate=0.2830308924238449,\n","#                               n_estimators=10,\n","#                               subsample=0.815750979360025,\n","#                               colsample_bytree=0.7782680870025142,\n","#                               gamma=0.007652270145192375,\n","#                               objective=\"binary:logistic\",\n","#                               random_state=42)\n","\n","# xgb_model.fit(x_train, np.squeeze(y_train))\n","# predict = xgb_model.predict(x_test)\n","\n","# # xgb.plot_importance(xgb_model)\n","\n","# get_report(y_test, predict, plot=True)\n","# # get_feature_importance(features, xgb_model.feature_importances_, plot=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7u2ZElDsYh_L","colab_type":"code","colab":{}},"source":["# ### Binary enconding columns ###\n","# dfNN_train = train[features].copy()\n","# dfNN_test = test[features].copy()\n","\n","# cols = [(32, 'CompanyKey'),\n","#         (32, 'CustomerKey'),\n","#         (32, 'CustomerRegion'),\n","#         (32, 'PaymentTerms'),\n","#         (3, 'DocumentDateWeekDay'),\n","#         (3, 'DueDateWeekDay')]\n","\n","# dfNN_train = binary_encoding(dfNN_train, cols)\n","# dfNN_test = binary_encoding(dfNN_test, cols)\n","\n","# dfNN_train.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSBwzRXvoaAs","colab_type":"code","colab":{}},"source":["# x_train, x_valid, y_train, y_valid = train_test_split(dfNN_train.values,\n","#                                                       train[y_column].values,\n","#                                                       test_size=0.1, \n","#                                                       shuffle=True,\n","#                                                       random_state=42,\n","#                                                       stratify=train[y_column].values)\n","\n","# y_train_categorical = tf.keras.utils.to_categorical(y_train)\n","# y_valid_categorical = tf.keras.utils.to_categorical(y_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wPaUTsS4Mt_","colab_type":"code","colab":{}},"source":["# def create_model():\n","#     model = tf.keras.models.Sequential(name='cubricks')\n","\n","#     model.add(tf.keras.layers.Input(shape=dfNN_train.values.shape[1]))\n","#     model.add(tf.keras.layers.BatchNormalization(renorm=True))\n","\n","#     model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)))\n","#     # model.add(tf.keras.layers.Dense(512, activation='relu'))\n","#     model.add(tf.keras.layers.BatchNormalization(renorm=True))\n","#     model.add(tf.keras.layers.Dropout(rate=0.1))\n","\n","#     model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)))\n","#     # model.add(tf.keras.layers.Dense(512, activation='relu'))\n","#     model.add(tf.keras.layers.BatchNormalization(renorm=True))\n","#     model.add(tf.keras.layers.Dropout(rate=0.1))\n","\n","#     model.add(tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)))\n","#     # model.add(tf.keras.layers.Dense(512, activation='relu'))\n","#     model.add(tf.keras.layers.BatchNormalization(renorm=True))\n","#     model.add(tf.keras.layers.Dropout(rate=0.1))\n","\n","#     model.add(tf.keras.layers.Dense(len(labels), activation='softmax'))\n","#     return model\n","\n","\n","# model = create_model()\n","\n","# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=1e-8, amsgrad=True),\n","#               loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1, reduction=tf.keras.losses.Reduction.SUM),\n","#               metrics=['accuracy'])\n","\n","# model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMHXBQZrVnR4","colab_type":"code","colab":{}},"source":["# logdir = os.path.join('.', 'output')\n","# training_log = os.path.join(logdir, 'training.txt')\n","# model_checkpoint = os.path.join(logdir, 'model.hdf5')\n","\n","# # os.makedirs(logdir, exist_ok=True)\n","\n","# # if os.path.isfile(model_checkpoint):\n","# #     model.load_weights(model_checkpoint)\n","\n","# callbacks = [\n","#     # tf.keras.callbacks.TensorBoard(logdir, profile_batch=0),\n","#     # tf.keras.callbacks.CSVLogger(training_log, separator=',', append=True),\n","#     # tf.keras.callbacks.ModelCheckpoint(model_checkpoint, monitor='val_loss', save_best_only=True, verbose=1),\n","#     # tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_delta=1e-8, factor=0.1, patience=10, verbose=1),\n","#     tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-8, patience=40, restore_best_weights=True, verbose=1),\n","# ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEdBnX1Q4gNb","colab_type":"code","colab":{}},"source":["# model.fit(x_train,\n","#           y_train_categorical,\n","#           validation_data=(x_valid, y_valid_categorical),\n","#           callbacks=callbacks,\n","#           batch_size=1024,\n","#           epochs=10000,\n","#           verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"74SPlPbDwnKS","colab_type":"code","colab":{}},"source":["# predict = np.argmax(model.predict(dfNN_test.values), axis=1)\n","# print(f'Total: {len(test[y_column].values)}')\n","# print(f'Accuracy: {accuracy_score(test[y_column].values, predict) * 100:.2f}%\\n')\n","\n","# cm_report = classification_report(y_test, predict, target_names=labels)\n","# print(cm_report)\n","\n","# cm = confusion_matrix(y_test, predict)\n","# plt.figure(figsize=(10, 10))\n","# sns.heatmap(cm/cm.sum(axis=0), square=True, annot=True, fmt='.2%', cmap='Blues', xticklabels=labels, yticklabels=labels)"],"execution_count":null,"outputs":[]}]}